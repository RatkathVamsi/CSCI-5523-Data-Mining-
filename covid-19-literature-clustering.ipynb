{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Literature Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Goal\n",
    "Given a large amount of literature and rapidly spreading COVID-19, it is difficult for a scientist to keep up with the research community promptly. Can we cluster similar research articles together to make it easier for health professionals to find relevant research articles? Clustering can be used to create a tool to identify similar articles, given a target article. It can also reduce the number of articles one has to go through as one can focus on a cluster of articles rather than all. \n",
    "\n",
    "**Approach**:\n",
    "<ol>\n",
    "    <li>Unsupervised Learning task, because we don't have labels for the articles</li>\n",
    "    <li>Clustering and Dimensionality Reduction task </li>\n",
    "    <li>See how well labels from K-Means classify</li>\n",
    "    <li>Use N-Grams with Hash Vectorizer</li>\n",
    "    <li>Use plain text with Tf-idf</li>\n",
    "    <li>Use K-Means for clustering</li>\n",
    "    <li>Use t-SNE for dimensionality reduction</li>\n",
    "    <li>Use PCA for dimensionality reduction</li>\n",
    "    <li>There is no continuous flow of data, no need to adjust to changing data, and the data is small enough to fit in memmory: Batch Learning</li>\n",
    "    <li>Altough, there is no continuous flow of data, our approach has to be scalable as there will be more literature later</li>\n",
    "</ol>\n",
    "\n",
    "### Dataset Description\n",
    "\n",
    ">*In response to the COVID-19 pandemic, the White House and a coalition of leading research groups have prepared the COVID-19 Open Research Dataset (CORD-19). CORD-19 is a resource of over 29,000 scholarly articles, including over 13,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses. This freely available dataset is provided to the global research community to apply recent advances in natural language processing and other AI techniques to generate new insights in support of the ongoing fight against this infectious disease. There is a growing urgency for these approaches because of the rapid acceleration in new coronavirus literature, making it difficult for the medical research community to keep up.*\n",
    "#### Cite: [COVID-19 Open Research Dataset Challenge (CORD-19) | Kaggle](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data\n",
    "Load the data following the notebook by Ivan Ega Pratama, from Kaggle.\n",
    "#### Cite: [Dataset Parsing Code | Kaggle, COVID EDA: Initial Exploration Tool](https://www.kaggle.com/ivanegapratama/covid-eda-initial-exploration-tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the metadata of the dateset. 'title' and 'journal' attributes may be useful later when we cluster the articles to see what kinds of articles cluster together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>sha</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>Microsoft Academic Paper ID</th>\n",
       "      <th>WHO #Covidence</th>\n",
       "      <th>has_pdf_parse</th>\n",
       "      <th>has_pmc_xml_parse</th>\n",
       "      <th>full_text_file</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xqhn0vbp</td>\n",
       "      <td>1e1286db212100993d03cc22374b624f7caee956</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Airborne rhinovirus detection and effect of ul...</td>\n",
       "      <td>10.1186/1471-2458-3-5</td>\n",
       "      <td>PMC140314</td>\n",
       "      <td>12525263</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>BACKGROUND: Rhinovirus, the most common cause ...</td>\n",
       "      <td>2003-01-13</td>\n",
       "      <td>Myatt, Theodore A; Johnston, Sebastian L; Rudn...</td>\n",
       "      <td>BMC Public Health</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>custom_license</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gi6uaa83</td>\n",
       "      <td>8ae137c8da1607b3a8e4c946c07ca8bda67f88ac</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Discovering human history from stomach bacteria</td>\n",
       "      <td>10.1186/gb-2003-4-5-213</td>\n",
       "      <td>PMC156578</td>\n",
       "      <td>12734001</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Recent analyses of human pathogens have reveal...</td>\n",
       "      <td>2003-04-28</td>\n",
       "      <td>Disotell, Todd R</td>\n",
       "      <td>Genome Biol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>custom_license</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>le0ogx1s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMC</td>\n",
       "      <td>A new recruit for the army of the men of death</td>\n",
       "      <td>10.1186/gb-2003-4-7-113</td>\n",
       "      <td>PMC193621</td>\n",
       "      <td>12844350</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>The army of the men of death, in John Bunyan's...</td>\n",
       "      <td>2003-06-27</td>\n",
       "      <td>Petsko, Gregory A</td>\n",
       "      <td>Genome Biol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>custom_license</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fy4w7xz8</td>\n",
       "      <td>0104f6ceccf92ae8567a0102f89cbb976969a774</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Association of HLA class I with severe acute r...</td>\n",
       "      <td>10.1186/1471-2350-4-9</td>\n",
       "      <td>PMC212558</td>\n",
       "      <td>12969506</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>BACKGROUND: The human leukocyte antigen (HLA) ...</td>\n",
       "      <td>2003-09-12</td>\n",
       "      <td>Lin, Marie; Tseng, Hsiang-Kuang; Trejaut, Jean...</td>\n",
       "      <td>BMC Med Genet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>custom_license</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0qaoam29</td>\n",
       "      <td>5b68a553a7cbbea13472721cd1ad617d42b40c26</td>\n",
       "      <td>PMC</td>\n",
       "      <td>A double epidemic model for the SARS propagation</td>\n",
       "      <td>10.1186/1471-2334-3-19</td>\n",
       "      <td>PMC222908</td>\n",
       "      <td>12964944</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>BACKGROUND: An epidemic of a Severe Acute Resp...</td>\n",
       "      <td>2003-09-10</td>\n",
       "      <td>Ng, Tuen Wai; Turinici, Gabriel; Danchin, Antoine</td>\n",
       "      <td>BMC Infect Dis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>custom_license</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cord_uid                                       sha source_x  \\\n",
       "0  xqhn0vbp  1e1286db212100993d03cc22374b624f7caee956      PMC   \n",
       "1  gi6uaa83  8ae137c8da1607b3a8e4c946c07ca8bda67f88ac      PMC   \n",
       "2  le0ogx1s                                       NaN      PMC   \n",
       "3  fy4w7xz8  0104f6ceccf92ae8567a0102f89cbb976969a774      PMC   \n",
       "4  0qaoam29  5b68a553a7cbbea13472721cd1ad617d42b40c26      PMC   \n",
       "\n",
       "                                               title                      doi  \\\n",
       "0  Airborne rhinovirus detection and effect of ul...    10.1186/1471-2458-3-5   \n",
       "1    Discovering human history from stomach bacteria  10.1186/gb-2003-4-5-213   \n",
       "2     A new recruit for the army of the men of death  10.1186/gb-2003-4-7-113   \n",
       "3  Association of HLA class I with severe acute r...    10.1186/1471-2350-4-9   \n",
       "4   A double epidemic model for the SARS propagation   10.1186/1471-2334-3-19   \n",
       "\n",
       "       pmcid pubmed_id license  \\\n",
       "0  PMC140314  12525263   no-cc   \n",
       "1  PMC156578  12734001   no-cc   \n",
       "2  PMC193621  12844350   no-cc   \n",
       "3  PMC212558  12969506   no-cc   \n",
       "4  PMC222908  12964944   no-cc   \n",
       "\n",
       "                                            abstract publish_time  \\\n",
       "0  BACKGROUND: Rhinovirus, the most common cause ...   2003-01-13   \n",
       "1  Recent analyses of human pathogens have reveal...   2003-04-28   \n",
       "2  The army of the men of death, in John Bunyan's...   2003-06-27   \n",
       "3  BACKGROUND: The human leukocyte antigen (HLA) ...   2003-09-12   \n",
       "4  BACKGROUND: An epidemic of a Severe Acute Resp...   2003-09-10   \n",
       "\n",
       "                                             authors            journal  \\\n",
       "0  Myatt, Theodore A; Johnston, Sebastian L; Rudn...  BMC Public Health   \n",
       "1                                   Disotell, Todd R        Genome Biol   \n",
       "2                                  Petsko, Gregory A        Genome Biol   \n",
       "3  Lin, Marie; Tseng, Hsiang-Kuang; Trejaut, Jean...      BMC Med Genet   \n",
       "4  Ng, Tuen Wai; Turinici, Gabriel; Danchin, Antoine     BMC Infect Dis   \n",
       "\n",
       "  Microsoft Academic Paper ID WHO #Covidence  has_pdf_parse  \\\n",
       "0                         NaN            NaN           True   \n",
       "1                         NaN            NaN           True   \n",
       "2                         NaN            NaN          False   \n",
       "3                         NaN            NaN           True   \n",
       "4                         NaN            NaN           True   \n",
       "\n",
       "   has_pmc_xml_parse  full_text_file  \\\n",
       "0               True  custom_license   \n",
       "1               True  custom_license   \n",
       "2               True  custom_license   \n",
       "3               True  custom_license   \n",
       "4               True  custom_license   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1...  \n",
       "1  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1...  \n",
       "2  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1...  \n",
       "3  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2...  \n",
       "4  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = 'CORD-19-research-challenge/'\n",
    "metadata_path = f'{root_path}/metadata.csv'\n",
    "meta_df = pd.read_csv(metadata_path, dtype={\n",
    "    'pubmed_id': str,\n",
    "    'Microsoft Academic Paper ID': str, \n",
    "    'doi': str\n",
    "})\n",
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51078 entries, 0 to 51077\n",
      "Data columns (total 18 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   cord_uid                     51078 non-null  object\n",
      " 1   sha                          38022 non-null  object\n",
      " 2   source_x                     51078 non-null  object\n",
      " 3   title                        50920 non-null  object\n",
      " 4   doi                          47741 non-null  object\n",
      " 5   pmcid                        41082 non-null  object\n",
      " 6   pubmed_id                    37861 non-null  object\n",
      " 7   license                      51078 non-null  object\n",
      " 8   abstract                     42351 non-null  object\n",
      " 9   publish_time                 51070 non-null  object\n",
      " 10  authors                      48891 non-null  object\n",
      " 11  journal                      46368 non-null  object\n",
      " 12  Microsoft Academic Paper ID  964 non-null    object\n",
      " 13  WHO #Covidence               1768 non-null   object\n",
      " 14  has_pdf_parse                51078 non-null  bool  \n",
      " 15  has_pmc_xml_parse            51078 non-null  bool  \n",
      " 16  full_text_file               42511 non-null  object\n",
      " 17  url                          50776 non-null  object\n",
      "dtypes: bool(2), object(16)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "meta_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch All of JSON File Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get path to all JSON files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59311"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_json = glob.glob(f'{root_path}/**/*.json', recursive=True)\n",
    "len(all_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " File Reader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileReader:\n",
    "    def __init__(self, file_path):\n",
    "        with open(file_path) as file:\n",
    "            content = json.load(file)\n",
    "            self.paper_id = content['paper_id']\n",
    "            self.abstract = []\n",
    "            self.body_text = []\n",
    "            # Abstract\n",
    "            for entry in content['abstract']:\n",
    "                self.abstract.append(entry['text'])\n",
    "            # Body text\n",
    "            for entry in content['body_text']:\n",
    "                self.body_text.append(entry['text'])\n",
    "            self.abstract = '\\n'.join(self.abstract)\n",
    "            self.body_text = '\\n'.join(self.body_text)\n",
    "    def __repr__(self):\n",
    "        return f'{self.paper_id}: {self.abstract[:200]}... {self.body_text[:200]}...'\n",
    "    \n",
    "# Helper function adds break after every words when character length reach to certain amount. This is for the interactive plot so that hover tool fits the screen.\n",
    "    \n",
    "def get_breaks(content, length):\n",
    "    data = \"\"\n",
    "    words = content.split(' ')\n",
    "    total_chars = 0\n",
    "\n",
    "    # add break every length characters\n",
    "    for i in range(len(words)):\n",
    "        total_chars += len(words[i])\n",
    "        if total_chars > length:\n",
    "            data = data + \"<br>\" + words[i]\n",
    "            total_chars = 0\n",
    "        else:\n",
    "            data = data + \" \" + words[i]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data into DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the helper functions, let's read in the articles into a DataFrame that can be used easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing index: 0 of 59311\n",
      "Processing index: 5931 of 59311\n",
      "Processing index: 11862 of 59311\n",
      "Processing index: 17793 of 59311\n",
      "Processing index: 23724 of 59311\n",
      "Processing index: 29655 of 59311\n",
      "Processing index: 35586 of 59311\n",
      "Processing index: 41517 of 59311\n",
      "Processing index: 47448 of 59311\n",
      "Processing index: 53379 of 59311\n",
      "Processing index: 59310 of 59311\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>journal</th>\n",
       "      <th>abstract_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0015023cc06b5362d332b3baf348d11567ca2fbb</td>\n",
       "      <td>word count: 194 22 Text word count: 5168 23 24...</td>\n",
       "      <td>VP3, and VP0 (which is further processed to VP...</td>\n",
       "      <td>Joseph C. Ward.  Lidia Lasecka-Dykes...</td>\n",
       "      <td>The RNA pseudoknots in foot-and-mouth disease...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>word count: 194 22 Text word count: 5168 23 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00340eea543336d54adda18236424de6a5e91c9d</td>\n",
       "      <td>During the past three months, a new coronaviru...</td>\n",
       "      <td>In December 2019, a novel coronavirus, SARS-Co...</td>\n",
       "      <td>Carla Mavian.  Simone Marini...</td>\n",
       "      <td>Regaining perspective on SARS-CoV-2&lt;br&gt;molecu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>During the past three months, a new coronavir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004f0f8bb66cf446678dc13cf2701feec4f36d76</td>\n",
       "      <td></td>\n",
       "      <td>The 2019-nCoV epidemic has spread across China...</td>\n",
       "      <td>Hanchu Zhou.  Jianan Yang...</td>\n",
       "      <td>Healthcare-resource-adjusted&lt;br&gt;vulnerabiliti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not provided.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00911cf4f99a3d5ae5e5b787675646a743574496</td>\n",
       "      <td>The fast accumulation of viral metagenomic dat...</td>\n",
       "      <td>Metagenomic sequencing, which allows us to dir...</td>\n",
       "      <td>Jiayu Shang.  Yanni Sun</td>\n",
       "      <td>CHEER: hierarCHical taxonomic&lt;br&gt;classificati...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The fast accumulation of viral metagenomic&lt;br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00d16927588fb04d4be0e6b269fc02f0d3c2aa7b</td>\n",
       "      <td>Infectious bronchitis (IB) causes significant ...</td>\n",
       "      <td>Infectious bronchitis (IB), which is caused by...</td>\n",
       "      <td>Salman L. Butt.  Eric C. Erwood...</td>\n",
       "      <td>Real-time, MinION-based, amplicon&lt;br&gt;sequenci...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Infectious bronchitis (IB) causes&lt;br&gt;signific...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id  \\\n",
       "0  0015023cc06b5362d332b3baf348d11567ca2fbb   \n",
       "1  00340eea543336d54adda18236424de6a5e91c9d   \n",
       "2  004f0f8bb66cf446678dc13cf2701feec4f36d76   \n",
       "3  00911cf4f99a3d5ae5e5b787675646a743574496   \n",
       "4  00d16927588fb04d4be0e6b269fc02f0d3c2aa7b   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  word count: 194 22 Text word count: 5168 23 24...   \n",
       "1  During the past three months, a new coronaviru...   \n",
       "2                                                      \n",
       "3  The fast accumulation of viral metagenomic dat...   \n",
       "4  Infectious bronchitis (IB) causes significant ...   \n",
       "\n",
       "                                           body_text  \\\n",
       "0  VP3, and VP0 (which is further processed to VP...   \n",
       "1  In December 2019, a novel coronavirus, SARS-Co...   \n",
       "2  The 2019-nCoV epidemic has spread across China...   \n",
       "3  Metagenomic sequencing, which allows us to dir...   \n",
       "4  Infectious bronchitis (IB), which is caused by...   \n",
       "\n",
       "                                   authors  \\\n",
       "0  Joseph C. Ward.  Lidia Lasecka-Dykes...   \n",
       "1          Carla Mavian.  Simone Marini...   \n",
       "2             Hanchu Zhou.  Jianan Yang...   \n",
       "3                  Jiayu Shang.  Yanni Sun   \n",
       "4       Salman L. Butt.  Eric C. Erwood...   \n",
       "\n",
       "                                               title journal  \\\n",
       "0   The RNA pseudoknots in foot-and-mouth disease...     NaN   \n",
       "1   Regaining perspective on SARS-CoV-2<br>molecu...     NaN   \n",
       "2   Healthcare-resource-adjusted<br>vulnerabiliti...     NaN   \n",
       "3   CHEER: hierarCHical taxonomic<br>classificati...     NaN   \n",
       "4   Real-time, MinION-based, amplicon<br>sequenci...     NaN   \n",
       "\n",
       "                                    abstract_summary  \n",
       "0   word count: 194 22 Text word count: 5168 23 2...  \n",
       "1   During the past three months, a new coronavir...  \n",
       "2                                      Not provided.  \n",
       "3   The fast accumulation of viral metagenomic<br...  \n",
       "4   Infectious bronchitis (IB) causes<br>signific...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_ = {'paper_id': [], 'abstract': [], 'body_text': [], 'authors': [], 'title': [], 'journal': [], 'abstract_summary': []}\n",
    "for idx, entry in enumerate(all_json):\n",
    "    try:\n",
    "        if idx % (len(all_json) // 10) == 0:\n",
    "            print(f'Processing index: {idx} of {len(all_json)}')\n",
    "        content = FileReader(entry)\n",
    "\n",
    "        # get metadata information\n",
    "        meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n",
    "        # no metadata, skip this paper\n",
    "        if len(meta_data) == 0:\n",
    "            continue\n",
    "\n",
    "        dict_['paper_id'].append(content.paper_id)\n",
    "        dict_['abstract'].append(content.abstract)\n",
    "        dict_['body_text'].append(content.body_text)\n",
    "\n",
    "        # also create a column for the summary of abstract to be used in a plot\n",
    "        if len(content.abstract) == 0: \n",
    "            # no abstract provided\n",
    "            dict_['abstract_summary'].append(\"Not provided.\")\n",
    "        elif len(content.abstract.split(' ')) > 100:\n",
    "            # abstract provided is too long for plot, take first 300 words append with ...\n",
    "            info = content.abstract.split(' ')[:100]\n",
    "            summary = get_breaks(' '.join(info), 40)\n",
    "            dict_['abstract_summary'].append(summary + \"...\")\n",
    "        else:\n",
    "            # abstract is short enough\n",
    "            summary = get_breaks(content.abstract, 40)\n",
    "            dict_['abstract_summary'].append(summary)\n",
    "\n",
    "        # get metadata information\n",
    "        meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n",
    "\n",
    "        try:\n",
    "            # if more than one author\n",
    "            authors = meta_data['authors'].values[0].split(';')\n",
    "            if len(authors) > 2:\n",
    "                # more than 2 authors, may be problem when plotting, so take first 2 append with ...\n",
    "                dict_['authors'].append(\". \".join(authors[:2]) + \"...\")\n",
    "            else:\n",
    "                # authors will fit in plot\n",
    "                dict_['authors'].append(\". \".join(authors))\n",
    "        except Exception as e:\n",
    "            # if only one author - or Null valie\n",
    "            dict_['authors'].append(meta_data['authors'].values[0])\n",
    "\n",
    "        # add the title information, add breaks when needed\n",
    "        try:\n",
    "            title = get_breaks(meta_data['title'].values[0], 40)\n",
    "            dict_['title'].append(title)\n",
    "        # if title was not provided\n",
    "        except Exception as e:\n",
    "            dict_['title'].append(meta_data['title'].values[0])\n",
    "\n",
    "        # add the journal information\n",
    "        dict_['journal'].append(meta_data['journal'].values[0])\n",
    "        \n",
    "    \n",
    "    except Exception as e:\n",
    "        continue\n",
    "    \n",
    "df_covid = pd.DataFrame(dict_, columns=['paper_id', 'abstract', 'body_text', 'authors', 'title', 'journal', 'abstract_summary'])\n",
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding the Word Count Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding word count columns for both abstract and body_text can be useful parameters later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>journal</th>\n",
       "      <th>abstract_summary</th>\n",
       "      <th>abstract_word_count</th>\n",
       "      <th>body_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0015023cc06b5362d332b3baf348d11567ca2fbb</td>\n",
       "      <td>word count: 194 22 Text word count: 5168 23 24...</td>\n",
       "      <td>VP3, and VP0 (which is further processed to VP...</td>\n",
       "      <td>Joseph C. Ward.  Lidia Lasecka-Dykes...</td>\n",
       "      <td>The RNA pseudoknots in foot-and-mouth disease...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>word count: 194 22 Text word count: 5168 23 2...</td>\n",
       "      <td>241</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00340eea543336d54adda18236424de6a5e91c9d</td>\n",
       "      <td>During the past three months, a new coronaviru...</td>\n",
       "      <td>In December 2019, a novel coronavirus, SARS-Co...</td>\n",
       "      <td>Carla Mavian.  Simone Marini...</td>\n",
       "      <td>Regaining perspective on SARS-CoV-2&lt;br&gt;molecu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>During the past three months, a new coronavir...</td>\n",
       "      <td>175</td>\n",
       "      <td>2549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004f0f8bb66cf446678dc13cf2701feec4f36d76</td>\n",
       "      <td></td>\n",
       "      <td>The 2019-nCoV epidemic has spread across China...</td>\n",
       "      <td>Hanchu Zhou.  Jianan Yang...</td>\n",
       "      <td>Healthcare-resource-adjusted&lt;br&gt;vulnerabiliti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not provided.</td>\n",
       "      <td>0</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00911cf4f99a3d5ae5e5b787675646a743574496</td>\n",
       "      <td>The fast accumulation of viral metagenomic dat...</td>\n",
       "      <td>Metagenomic sequencing, which allows us to dir...</td>\n",
       "      <td>Jiayu Shang.  Yanni Sun</td>\n",
       "      <td>CHEER: hierarCHical taxonomic&lt;br&gt;classificati...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The fast accumulation of viral metagenomic&lt;br...</td>\n",
       "      <td>139</td>\n",
       "      <td>5188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00d16927588fb04d4be0e6b269fc02f0d3c2aa7b</td>\n",
       "      <td>Infectious bronchitis (IB) causes significant ...</td>\n",
       "      <td>Infectious bronchitis (IB), which is caused by...</td>\n",
       "      <td>Salman L. Butt.  Eric C. Erwood...</td>\n",
       "      <td>Real-time, MinION-based, amplicon&lt;br&gt;sequenci...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Infectious bronchitis (IB) causes&lt;br&gt;signific...</td>\n",
       "      <td>1647</td>\n",
       "      <td>4003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id  \\\n",
       "0  0015023cc06b5362d332b3baf348d11567ca2fbb   \n",
       "1  00340eea543336d54adda18236424de6a5e91c9d   \n",
       "2  004f0f8bb66cf446678dc13cf2701feec4f36d76   \n",
       "3  00911cf4f99a3d5ae5e5b787675646a743574496   \n",
       "4  00d16927588fb04d4be0e6b269fc02f0d3c2aa7b   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  word count: 194 22 Text word count: 5168 23 24...   \n",
       "1  During the past three months, a new coronaviru...   \n",
       "2                                                      \n",
       "3  The fast accumulation of viral metagenomic dat...   \n",
       "4  Infectious bronchitis (IB) causes significant ...   \n",
       "\n",
       "                                           body_text  \\\n",
       "0  VP3, and VP0 (which is further processed to VP...   \n",
       "1  In December 2019, a novel coronavirus, SARS-Co...   \n",
       "2  The 2019-nCoV epidemic has spread across China...   \n",
       "3  Metagenomic sequencing, which allows us to dir...   \n",
       "4  Infectious bronchitis (IB), which is caused by...   \n",
       "\n",
       "                                   authors  \\\n",
       "0  Joseph C. Ward.  Lidia Lasecka-Dykes...   \n",
       "1          Carla Mavian.  Simone Marini...   \n",
       "2             Hanchu Zhou.  Jianan Yang...   \n",
       "3                  Jiayu Shang.  Yanni Sun   \n",
       "4       Salman L. Butt.  Eric C. Erwood...   \n",
       "\n",
       "                                               title journal  \\\n",
       "0   The RNA pseudoknots in foot-and-mouth disease...     NaN   \n",
       "1   Regaining perspective on SARS-CoV-2<br>molecu...     NaN   \n",
       "2   Healthcare-resource-adjusted<br>vulnerabiliti...     NaN   \n",
       "3   CHEER: hierarCHical taxonomic<br>classificati...     NaN   \n",
       "4   Real-time, MinION-based, amplicon<br>sequenci...     NaN   \n",
       "\n",
       "                                    abstract_summary  abstract_word_count  \\\n",
       "0   word count: 194 22 Text word count: 5168 23 2...                  241   \n",
       "1   During the past three months, a new coronavir...                  175   \n",
       "2                                      Not provided.                    0   \n",
       "3   The fast accumulation of viral metagenomic<br...                  139   \n",
       "4   Infectious bronchitis (IB) causes<br>signific...                 1647   \n",
       "\n",
       "   body_word_count  \n",
       "0             1728  \n",
       "1             2549  \n",
       "2              755  \n",
       "3             5188  \n",
       "4             4003  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid['abstract_word_count'] = df_covid['abstract'].apply(lambda x: len(x.strip().split()))\n",
    "df_covid['body_word_count'] = df_covid['body_text'].apply(lambda x: len(x.strip().split()))\n",
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     36009\n",
       "unique    26249\n",
       "top            \n",
       "freq       9704\n",
       "Name: abstract, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid['abstract'].describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing-Handle Possible Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at the unique values above, we can see that there are duplicates. It may have caused because of author submiting the article to multiple journals. Let's remove the duplicats from our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                 24584\n",
       "unique                                                24552\n",
       "top       Travel Medicine and Infectious Disease xxx (xx...\n",
       "freq                                                      5\n",
       "Name: abstract, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid.dropna(inplace=True)\n",
    "df_covid = df_covid[df_covid.abstract != ''] #Remove rows which are missing abstracts\n",
    "df_covid = df_covid[df_covid.body_text != ''] #Remove rows which are missing body_text\n",
    "df_covid.drop_duplicates(['abstract', 'body_text'], inplace=True) # remove duplicate rows having same abstract and body_text\n",
    "df_covid['abstract'].describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                 24584\n",
       "unique                                                24584\n",
       "top       iNTRODUCTiON Human beings are constantly expos...\n",
       "freq                                                      1\n",
       "Name: body_text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid['body_text'].describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we didn't have duplicates. Instead, it was articles without Abstracts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a Look at the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>journal</th>\n",
       "      <th>abstract_summary</th>\n",
       "      <th>abstract_word_count</th>\n",
       "      <th>body_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>00142f93c18b07350be89e96372d240372437ed9</td>\n",
       "      <td>Dendritic cells (DCs) are specialized antigen-...</td>\n",
       "      <td>iNTRODUCTiON Human beings are constantly expos...</td>\n",
       "      <td>Geginat, Jens.  Nizzoli, Giulia...</td>\n",
       "      <td>Immunity to Pathogens Taught by Specialized&lt;b...</td>\n",
       "      <td>Front Immunol</td>\n",
       "      <td>Dendritic cells (DCs) are specialized&lt;br&gt;anti...</td>\n",
       "      <td>309</td>\n",
       "      <td>5305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>0022796bb2112abd2e6423ba2d57751db06049fb</td>\n",
       "      <td>Dengue has a negative impact in low-and lower ...</td>\n",
       "      <td>Pathogens and vectors can now be transported r...</td>\n",
       "      <td>Viennet, Elvina.  Ritchie, Scott A....</td>\n",
       "      <td>Public Health Responses to and Challenges for...</td>\n",
       "      <td>PLoS Negl Trop Dis</td>\n",
       "      <td>Dengue has a negative impact in low-and lower...</td>\n",
       "      <td>276</td>\n",
       "      <td>7288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>0031e47b76374e05a18c266bd1a1140e5eacb54f</td>\n",
       "      <td>Fecal microbial transplantation (FMT), a treat...</td>\n",
       "      <td>a1111111111 a1111111111 a1111111111 a111111111...</td>\n",
       "      <td>McKinney, Caroline A..  Oliveira, Bruno C. M....</td>\n",
       "      <td>The fecal microbiota of healthy donor horses&lt;...</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>Fecal microbial transplantation (FMT), a&lt;br&gt;t...</td>\n",
       "      <td>141</td>\n",
       "      <td>4669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>00326efcca0852dc6e39dc6b7786267e1bc4f194</td>\n",
       "      <td>Fifteen years ago, United Nations world leader...</td>\n",
       "      <td>In addition to preventative care and nutrition...</td>\n",
       "      <td>Turner, Erin L..  Nielsen, Katie R....</td>\n",
       "      <td>A Review of Pediatric Critical Care in&lt;br&gt;Res...</td>\n",
       "      <td>Front Pediatr</td>\n",
       "      <td>Fifteen years ago, United Nations world&lt;br&gt;le...</td>\n",
       "      <td>151</td>\n",
       "      <td>7593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>00352a58c8766861effed18a4b079d1683fec2ec</td>\n",
       "      <td>Posttranslational modification of proteins by ...</td>\n",
       "      <td>Ubiquitination is a widely used posttranslatio...</td>\n",
       "      <td>Hodul, Molly.  Dahlberg, Caroline L....</td>\n",
       "      <td>Function of the Deubiquitinating Enzyme USP46...</td>\n",
       "      <td>Front Synaptic Neurosci</td>\n",
       "      <td>Posttranslational modification of proteins&lt;br...</td>\n",
       "      <td>148</td>\n",
       "      <td>3156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      paper_id  \\\n",
       "1625  00142f93c18b07350be89e96372d240372437ed9   \n",
       "1626  0022796bb2112abd2e6423ba2d57751db06049fb   \n",
       "1627  0031e47b76374e05a18c266bd1a1140e5eacb54f   \n",
       "1628  00326efcca0852dc6e39dc6b7786267e1bc4f194   \n",
       "1629  00352a58c8766861effed18a4b079d1683fec2ec   \n",
       "\n",
       "                                               abstract  \\\n",
       "1625  Dendritic cells (DCs) are specialized antigen-...   \n",
       "1626  Dengue has a negative impact in low-and lower ...   \n",
       "1627  Fecal microbial transplantation (FMT), a treat...   \n",
       "1628  Fifteen years ago, United Nations world leader...   \n",
       "1629  Posttranslational modification of proteins by ...   \n",
       "\n",
       "                                              body_text  \\\n",
       "1625  iNTRODUCTiON Human beings are constantly expos...   \n",
       "1626  Pathogens and vectors can now be transported r...   \n",
       "1627  a1111111111 a1111111111 a1111111111 a111111111...   \n",
       "1628  In addition to preventative care and nutrition...   \n",
       "1629  Ubiquitination is a widely used posttranslatio...   \n",
       "\n",
       "                                               authors  \\\n",
       "1625                Geginat, Jens.  Nizzoli, Giulia...   \n",
       "1626            Viennet, Elvina.  Ritchie, Scott A....   \n",
       "1627  McKinney, Caroline A..  Oliveira, Bruno C. M....   \n",
       "1628            Turner, Erin L..  Nielsen, Katie R....   \n",
       "1629           Hodul, Molly.  Dahlberg, Caroline L....   \n",
       "\n",
       "                                                  title  \\\n",
       "1625   Immunity to Pathogens Taught by Specialized<b...   \n",
       "1626   Public Health Responses to and Challenges for...   \n",
       "1627   The fecal microbiota of healthy donor horses<...   \n",
       "1628   A Review of Pediatric Critical Care in<br>Res...   \n",
       "1629   Function of the Deubiquitinating Enzyme USP46...   \n",
       "\n",
       "                      journal  \\\n",
       "1625            Front Immunol   \n",
       "1626       PLoS Negl Trop Dis   \n",
       "1627                 PLoS One   \n",
       "1628            Front Pediatr   \n",
       "1629  Front Synaptic Neurosci   \n",
       "\n",
       "                                       abstract_summary  abstract_word_count  \\\n",
       "1625   Dendritic cells (DCs) are specialized<br>anti...                  309   \n",
       "1626   Dengue has a negative impact in low-and lower...                  276   \n",
       "1627   Fecal microbial transplantation (FMT), a<br>t...                  141   \n",
       "1628   Fifteen years ago, United Nations world<br>le...                  151   \n",
       "1629   Posttranslational modification of proteins<br...                  148   \n",
       "\n",
       "      body_word_count  \n",
       "1625             5305  \n",
       "1626             7288  \n",
       "1627             4669  \n",
       "1628             7593  \n",
       "1629             3156  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 24584 entries, 1625 to 36008\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   paper_id             24584 non-null  object\n",
      " 1   abstract             24584 non-null  object\n",
      " 2   body_text            24584 non-null  object\n",
      " 3   authors              24584 non-null  object\n",
      " 4   title                24584 non-null  object\n",
      " 5   journal              24584 non-null  object\n",
      " 6   abstract_summary     24584 non-null  object\n",
      " 7   abstract_word_count  24584 non-null  int64 \n",
      " 8   body_word_count      24584 non-null  int64 \n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_covid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_word_count</th>\n",
       "      <th>body_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24584.000000</td>\n",
       "      <td>24584.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>216.446673</td>\n",
       "      <td>4435.475106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>137.065117</td>\n",
       "      <td>3657.421423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>147.000000</td>\n",
       "      <td>2711.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>3809.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>255.000000</td>\n",
       "      <td>5431.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3694.000000</td>\n",
       "      <td>232431.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       abstract_word_count  body_word_count\n",
       "count         24584.000000     24584.000000\n",
       "mean            216.446673      4435.475106\n",
       "std             137.065117      3657.421423\n",
       "min               1.000000        23.000000\n",
       "25%             147.000000      2711.000000\n",
       "50%             200.000000      3809.500000\n",
       "75%             255.000000      5431.000000\n",
       "max            3694.000000    232431.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our dataset loaded, we need to clean-up the text to improve any clustering or classification efforts. First, let's drop Null vales:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limit number of articles to speed up computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TA: Feel free to decrease this number if you think your system is getting stuck\n",
    "df_covid = df_covid.head(5523)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's remove punctuation from each text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df_covid['body_text'] = df_covid['body_text'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))\n",
    "df_covid['abstract'] = df_covid['abstract'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert each text to lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(input_str):\n",
    "    input_str = input_str.lower()\n",
    "    return input_str\n",
    "\n",
    "df_covid['body_text'] = df_covid['body_text'].apply(lambda x: lower_case(x))\n",
    "df_covid['abstract'] = df_covid['abstract'].apply(lambda x: lower_case(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>journal</th>\n",
       "      <th>abstract_summary</th>\n",
       "      <th>abstract_word_count</th>\n",
       "      <th>body_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>00142f93c18b07350be89e96372d240372437ed9</td>\n",
       "      <td>dendritic cells dcs are specialized antigenpre...</td>\n",
       "      <td>introduction human beings are constantly expos...</td>\n",
       "      <td>Geginat, Jens.  Nizzoli, Giulia...</td>\n",
       "      <td>Immunity to Pathogens Taught by Specialized&lt;b...</td>\n",
       "      <td>Front Immunol</td>\n",
       "      <td>Dendritic cells (DCs) are specialized&lt;br&gt;anti...</td>\n",
       "      <td>309</td>\n",
       "      <td>5305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>0022796bb2112abd2e6423ba2d57751db06049fb</td>\n",
       "      <td>dengue has a negative impact in lowand lower m...</td>\n",
       "      <td>pathogens and vectors can now be transported r...</td>\n",
       "      <td>Viennet, Elvina.  Ritchie, Scott A....</td>\n",
       "      <td>Public Health Responses to and Challenges for...</td>\n",
       "      <td>PLoS Negl Trop Dis</td>\n",
       "      <td>Dengue has a negative impact in low-and lower...</td>\n",
       "      <td>276</td>\n",
       "      <td>7288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>0031e47b76374e05a18c266bd1a1140e5eacb54f</td>\n",
       "      <td>fecal microbial transplantation fmt a treatmen...</td>\n",
       "      <td>a1111111111 a1111111111 a1111111111 a111111111...</td>\n",
       "      <td>McKinney, Caroline A..  Oliveira, Bruno C. M....</td>\n",
       "      <td>The fecal microbiota of healthy donor horses&lt;...</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>Fecal microbial transplantation (FMT), a&lt;br&gt;t...</td>\n",
       "      <td>141</td>\n",
       "      <td>4669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>00326efcca0852dc6e39dc6b7786267e1bc4f194</td>\n",
       "      <td>fifteen years ago united nations world leaders...</td>\n",
       "      <td>in addition to preventative care and nutrition...</td>\n",
       "      <td>Turner, Erin L..  Nielsen, Katie R....</td>\n",
       "      <td>A Review of Pediatric Critical Care in&lt;br&gt;Res...</td>\n",
       "      <td>Front Pediatr</td>\n",
       "      <td>Fifteen years ago, United Nations world&lt;br&gt;le...</td>\n",
       "      <td>151</td>\n",
       "      <td>7593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      paper_id  \\\n",
       "1625  00142f93c18b07350be89e96372d240372437ed9   \n",
       "1626  0022796bb2112abd2e6423ba2d57751db06049fb   \n",
       "1627  0031e47b76374e05a18c266bd1a1140e5eacb54f   \n",
       "1628  00326efcca0852dc6e39dc6b7786267e1bc4f194   \n",
       "\n",
       "                                               abstract  \\\n",
       "1625  dendritic cells dcs are specialized antigenpre...   \n",
       "1626  dengue has a negative impact in lowand lower m...   \n",
       "1627  fecal microbial transplantation fmt a treatmen...   \n",
       "1628  fifteen years ago united nations world leaders...   \n",
       "\n",
       "                                              body_text  \\\n",
       "1625  introduction human beings are constantly expos...   \n",
       "1626  pathogens and vectors can now be transported r...   \n",
       "1627  a1111111111 a1111111111 a1111111111 a111111111...   \n",
       "1628  in addition to preventative care and nutrition...   \n",
       "\n",
       "                                               authors  \\\n",
       "1625                Geginat, Jens.  Nizzoli, Giulia...   \n",
       "1626            Viennet, Elvina.  Ritchie, Scott A....   \n",
       "1627  McKinney, Caroline A..  Oliveira, Bruno C. M....   \n",
       "1628            Turner, Erin L..  Nielsen, Katie R....   \n",
       "\n",
       "                                                  title             journal  \\\n",
       "1625   Immunity to Pathogens Taught by Specialized<b...       Front Immunol   \n",
       "1626   Public Health Responses to and Challenges for...  PLoS Negl Trop Dis   \n",
       "1627   The fecal microbiota of healthy donor horses<...            PLoS One   \n",
       "1628   A Review of Pediatric Critical Care in<br>Res...       Front Pediatr   \n",
       "\n",
       "                                       abstract_summary  abstract_word_count  \\\n",
       "1625   Dendritic cells (DCs) are specialized<br>anti...                  309   \n",
       "1626   Dengue has a negative impact in low-and lower...                  276   \n",
       "1627   Fecal microbial transplantation (FMT), a<br>t...                  141   \n",
       "1628   Fifteen years ago, United Nations world<br>le...                  151   \n",
       "\n",
       "      body_word_count  \n",
       "1625             5305  \n",
       "1626             7288  \n",
       "1627             4669  \n",
       "1628             7593  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the text cleaned up, we can create our features vector which can be fed into a clustering or dimensionality reduction algorithm. For our first try, we will focus on the text on the body of the articles. Let's grab that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_covid.drop([\"paper_id\", \"abstract\", \"abstract_word_count\", \"body_word_count\", \"authors\", \"title\", \"journal\", \"abstract_summary\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>introduction human beings are constantly expos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>pathogens and vectors can now be transported r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>a1111111111 a1111111111 a1111111111 a111111111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>in addition to preventative care and nutrition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>ubiquitination is a widely used posttranslatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              body_text\n",
       "1625  introduction human beings are constantly expos...\n",
       "1626  pathogens and vectors can now be transported r...\n",
       "1627  a1111111111 a1111111111 a1111111111 a111111111...\n",
       "1628  in addition to preventative care and nutrition...\n",
       "1629  ubiquitination is a widely used posttranslatio..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform 1D DataFrame into 1D list where each index is an article (instance), so that we can work with words from each instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5523"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_arr = text.stack().tolist()\n",
    "len(text_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create 2D list, where each row is instance and each column is a word. Meaning, we will separate each instance into words:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for ii in range(0,len(text)):\n",
    "    words.append(str(text.iloc[ii]['body_text']).split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['introduction', 'human', 'beings', 'are', 'constantly', 'exposed', 'to', 'a', 'myriad', 'of', 'pathogens', 'including', 'bacteria', 'fungi', 'and', 'viruses', 'these', 'foreign', 'invaders', 'or']\n"
     ]
    }
   ],
   "source": [
    "print(words[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want now is n-grams from the words where n=2 (2-gram). We will still have 2D array where each row is an instance; however, each index in that row going to be a 2-gram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_all = []\n",
    "\n",
    "for word in words:\n",
    "    # get n-grams for the instance\n",
    "    n_gram = []\n",
    "    for i in range(len(word)-2+1):\n",
    "        n_gram.append(\"\".join(word[i:i+2]))\n",
    "    n_gram_all.append(n_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['introductionhuman',\n",
       " 'humanbeings',\n",
       " 'beingsare',\n",
       " 'areconstantly',\n",
       " 'constantlyexposed',\n",
       " 'exposedto',\n",
       " 'toa',\n",
       " 'amyriad',\n",
       " 'myriadof',\n",
       " 'ofpathogens']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_all[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize with HashingVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use HashVectorizer to create the features vector X. For now, let's limit the feature size to 2**12(4096) to speed up the computation. We might need to increase this later to reduce the collusions and improve the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# hash vectorizer instance\n",
    "hvec = HashingVectorizer(lowercase=False, analyzer=lambda l:l, n_features=2**12)\n",
    "\n",
    "# features matrix X\n",
    "X = hvec.fit_transform(n_gram_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5523, 4096)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separete Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: 4418\n",
      "X_test size: 1105 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# test set size of 20% of the data and the random seed 42 <3\n",
    "X_train, X_test = train_test_split(X.toarray(), test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train size:\", len(X_train))\n",
    "print(\"X_test size:\", len(X_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction with t-SNE\n",
    "Using t-SNE we can reduce our high dimensional features vector into 2 dimensional plane. In the process, t-SNE will keep similar instances together while trying to push different instances far from each other. Resulting 2-D plane can be useful to see which articles cluster near each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following cell will take 15-20 minutes to run\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(verbose=1, perplexity=5, init='random', learning_rate='auto')\n",
    "X_embedded = tsne.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sns settings\n",
    "sns.set(rc={'figure.figsize':(15,15)})\n",
    "\n",
    "# colors\n",
    "palette = sns.color_palette(\"bright\", 1)\n",
    "\n",
    "# plot\n",
    "sns.scatterplot(x=X_embedded[:,0], y=X_embedded[:,1], palette=palette)\n",
    "\n",
    "plt.title(\"t-SNE Covid-19 Articles\")\n",
    "# plt.savefig(\"plots/t-sne_covid19.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see few clusters forming. This may be a good sign that we are able to cluster similar articles together using 2-grams and HashVectorizer with 2**10 features. However, without labels it is difficult to see the clusters. For now, it looks like a blob of data... Let's try if we can use K-Means to generate our labels. We can later use this information to produce a scatterplot with labels to verify the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning: Clustering with K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using K-means we will get the labels we need. For now, we will create 10 clusters. I am choosing this arbitrarily. We can change this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following cell will take 4-5 minutes to run\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, verbose=10)\n",
    "y_pred = kmeans.fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels for the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = kmeans.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the labels, let's plot the t-SNE. scatterplot again and see if we have any obvious clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns settings\n",
    "sns.set(rc={'figure.figsize':(15,15)})\n",
    "\n",
    "# colors\n",
    "palette = sns.color_palette(\"bright\", len(set(y_pred)))\n",
    "\n",
    "# plot\n",
    "sns.scatterplot(x=X_embedded[:,0], y=X_embedded[:,1], hue=y_pred, legend='full', palette=palette)\n",
    "plt.title(\"t-SNE Covid-19 Articles - Clustered\")\n",
    "# plt.savefig(\"plots/t-sne_covid19_label.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty promising. It can be seen that articles from the same cluster are near each other, forming groups. There are still overlaps. So we will have to see if we can improve this by changing the cluster size, using another clustering algorithm, or different feature size. We can also consider not using 2-grams, or HashVectorizer. We can try 3-grams, 4-grams, or plain text as our instances and vectorize them using either HashVectorizer, Tf-idfVectorizer, or Burrows Wheeler Transform Distance. <br>\n",
    "\n",
    "Before we try another method for clustering, we want to see how well it will classify using the labels we just created using K-Means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print out classification model report\n",
    "def classification_report(model_name, test, pred):\n",
    "    from sklearn.metrics import precision_score, recall_score\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    \n",
    "    print(model_name, \":\\n\")\n",
    "    print(\"Accuracy Score: \", '{:,.3f}'.format(float(accuracy_score(test, pred)) * 100), \"%\")\n",
    "    print(\"     Precision: \", '{:,.3f}'.format(float(precision_score(test, pred, average='micro')) * 100), \"%\")\n",
    "    print(\"        Recall: \", '{:,.3f}'.format(float(recall_score(test, pred, average='micro')) * 100), \"%\")\n",
    "    print(\"      F1 score: \", '{:,.3f}'.format(float(f1_score(test, pred, average='micro')) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# random forest classifier instance\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# cross validation on the training set \n",
    "forest_scores = cross_val_score(forest_clf, X_train, y_train, cv=3, n_jobs=-1)\n",
    "\n",
    "# print out the mean of the cross validation scores\n",
    "print(\"Accuracy: \", '{:,.3f}'.format(float(forest_scores.mean()) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# cross validate predict on the training set\n",
    "forest_train_pred = cross_val_predict(forest_clf, X_train, y_train, cv=3, n_jobs=-1)\n",
    "\n",
    "# print precision and recall scores\n",
    "print(\"Precision: \", '{:,.3f}'.format(float(precision_score(y_train, forest_train_pred, average='macro')) * 100), \"%\")\n",
    "print(\"   Recall: \", '{:,.3f}'.format(float(recall_score(y_train, forest_train_pred, average='macro')) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first train the model\n",
    "forest_clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "forest_pred = forest_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the classification report\n",
    "classification_report(\"Random Forest Classifier Report (Test Set)\", y_test, forest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like it doesn't overfit, which is good news. But results can be better than ~70-80%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Using Tf-idf with Plain Text\n",
    "Let's see if we will be able to get better clusters using plain text as instances rather than 2-grams and vectorize it using Tf-idf. Last time we separated the dataset into test and training sets because we wanted to do classification with the labels we got through clustering. This time we will just use the all dataset because the goal is to cluster all literature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=2**12)\n",
    "X = vectorizer.fit_transform(df_covid['body_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniBatchKMeans with Plain text and Tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's try to get our labels. We will choose 10 clusters again. This time, we will use MiniBatchKMeans as it is faster with more data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "k = 19\n",
    "kmeans = MiniBatchKMeans(n_clusters=k)\n",
    "y_pred = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction with t-SNE (Plain text and Tf-idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reduce the dimensionality using t-SNE again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(verbose=1,init='random', learning_rate='auto')\n",
    "X_embedded = tsne.fit_transform(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sns settings\n",
    "sns.set(rc={'figure.figsize':(15,15)})\n",
    "\n",
    "# colors\n",
    "palette = sns.color_palette(\"bright\", len(set(y)))\n",
    "\n",
    "# plot\n",
    "sns.scatterplot(x=X_embedded[:,0], y=X_embedded[:,1], hue=y, legend='full', palette=palette)\n",
    "plt.title(\"t-SNE Covid-19 Articles - Clustered(K-Means) - Tf-idf with Plain Text\")\n",
    "# plt.savefig(\"plots/t-sne_covid19_label_TFID.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we are able to see the clusters more clearly. There are clusters that further apart from each other. I can also start to see that there is possibly more than 10 clusters we need to identify using k-means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction with PCA (Plain text and Tf-idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-SNE doesn't scale well. This is why run-time of this Notebook is about 40 minutes to 1 hour with an average computer. Let's try to see if we dan achive good results with PCA as it scales very well with larger datasets and dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns settings\n",
    "sns.set(rc={'figure.figsize':(15,15)})\n",
    "\n",
    "# colors\n",
    "palette = sns.color_palette(\"bright\", len(set(y)))\n",
    "\n",
    "# plot\n",
    "sns.scatterplot(x=pca_result[:,0], y=pca_result[:,1], hue=y, legend='full', palette=palette)\n",
    "plt.title(\"PCA Covid-19 Articles - Clustered (K-Means) - Tf-idf with Plain Text\")\n",
    "# plt.savefig(\"plots/pca_covid19_label_TFID.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it may be easier to see the results in a 3 dimensional plot. So let's try to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "ax = plt.figure(figsize=(16,10)).add_subplot(projection='3d')\n",
    "ax.scatter(\n",
    "    xs=pca_result[:,0], \n",
    "    ys=pca_result[:,1], \n",
    "    zs=pca_result[:,2], \n",
    "    c=y, \n",
    "    cmap='tab10'\n",
    ")\n",
    "ax.set_xlabel('pca-one')\n",
    "ax.set_ylabel('pca-two')\n",
    "ax.set_zlabel('pca-three')\n",
    "plt.title(\"PCA Covid-19 Articles (3D) - Clustered (K-Means) - Tf-idf with Plain Text\")\n",
    "# plt.savefig(\"plots/pca_covid19_label_TFID_3d.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Clusters?\n",
    "On our previous plot we could see that there is more clusters than only 10. Let's try to label them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "k = 20\n",
    "kmeans = MiniBatchKMeans(n_clusters=k)\n",
    "y_pred = kmeans.fit_predict(X)\n",
    "y = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import random \n",
    "\n",
    "# sns settings\n",
    "sns.set(rc={'figure.figsize':(15,15)})\n",
    "\n",
    "# let's shuffle the list so distinct colors stay next to each other\n",
    "palette = sns.hls_palette(20, l=.4, s=.9)\n",
    "random.shuffle(palette)\n",
    "\n",
    "# plot\n",
    "sns.scatterplot(x=X_embedded[:,0], y=X_embedded[:,1], hue=y, legend='full', palette=palette)\n",
    "plt.title(\"t-SNE Covid-19 Articles - Clustered(K-Means) - Tf-idf with Plain Text\")\n",
    "# plt.savefig(\"plots/t-sne_covid19_20label_TFID.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be helpful if we have a demo tool that can be used to see what articles are identified as similar using our Clustering and Dimensionality Reduction, right? Let's put together a interactive scatter plot of t-SNE to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import ColumnDataSource, HoverTool, LinearColorMapper, CustomJS\n",
    "from bokeh.palettes import Category20\n",
    "from bokeh.transform import linear_cmap\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.transform import transform\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import RadioButtonGroup\n",
    "from bokeh.models import TextInput\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import Div\n",
    "from bokeh.models import Paragraph\n",
    "from bokeh.layouts import column, widgetbox\n",
    "\n",
    "output_notebook()\n",
    "y_labels = y_pred\n",
    "\n",
    "# data sources\n",
    "source = ColumnDataSource(data=dict(\n",
    "    x= X_embedded[:,0], \n",
    "    y= X_embedded[:,1],\n",
    "    x_backup = X_embedded[:,0],\n",
    "    y_backup = X_embedded[:,1],\n",
    "    desc= y_labels, \n",
    "    titles= df_covid['title'],\n",
    "    authors = df_covid['authors'],\n",
    "    journal = df_covid['journal'],\n",
    "    abstract = df_covid['abstract_summary'],\n",
    "    labels = [\"C-\" + str(x) for x in y_labels]\n",
    "    ))\n",
    "\n",
    "# hover over information\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"Title\", \"@titles{safe}\"),\n",
    "    (\"Author(s)\", \"@authors\"),\n",
    "    (\"Journal\", \"@journal\"),\n",
    "    (\"Abstract\", \"@abstract{safe}\"),\n",
    "],\n",
    "                 point_policy=\"follow_mouse\")\n",
    "\n",
    "# map colors\n",
    "mapper = linear_cmap(field_name='desc', \n",
    "                     palette=Category20[20],\n",
    "                     low=min(y_labels) ,high=max(y_labels))\n",
    "\n",
    "# prepare the figure\n",
    "p = figure(plot_width=800, plot_height=800, \n",
    "           tools=[hover, 'pan', 'wheel_zoom', 'box_zoom', 'reset'], \n",
    "           title=\"t-SNE Covid-19 Articles, Clustered(K-Means), Tf-idf with Plain Text\", \n",
    "           toolbar_location=\"right\")\n",
    "\n",
    "# plot\n",
    "p.scatter('x', 'y', size=5, \n",
    "          source=source,\n",
    "          fill_color=mapper,\n",
    "          line_alpha=0.3,\n",
    "          line_color=\"black\",\n",
    "          legend_label = 'labels')\n",
    "\n",
    "# add callback to control \n",
    "callback = CustomJS(args=dict(p=p, source=source), code=\"\"\"\n",
    "            \n",
    "            var radio_value = cb_obj.active;\n",
    "            var data = source.data; \n",
    "            \n",
    "            x = data['x'];\n",
    "            y = data['y'];\n",
    "            \n",
    "            x_backup = data['x_backup'];\n",
    "            y_backup = data['y_backup'];\n",
    "            \n",
    "            labels = data['desc'];\n",
    "            \n",
    "            if (radio_value == '20') {\n",
    "                for (i = 0; i < x.length; i++) {\n",
    "                    x[i] = x_backup[i];\n",
    "                    y[i] = y_backup[i];\n",
    "                }\n",
    "            }\n",
    "            else {\n",
    "                for (i = 0; i < x.length; i++) {\n",
    "                    if(labels[i] == radio_value) {\n",
    "                        x[i] = x_backup[i];\n",
    "                        y[i] = y_backup[i];\n",
    "                    } else {\n",
    "                        x[i] = undefined;\n",
    "                        y[i] = undefined;\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "\n",
    "        source.change.emit();\n",
    "        \"\"\")\n",
    "\n",
    "# callback for searchbar\n",
    "keyword_callback = CustomJS(args=dict(p=p, source=source), code=\"\"\"\n",
    "            \n",
    "            var text_value = cb_obj.value;\n",
    "            var data = source.data; \n",
    "            \n",
    "            x = data['x'];\n",
    "            y = data['y'];\n",
    "            \n",
    "            x_backup = data['x_backup'];\n",
    "            y_backup = data['y_backup'];\n",
    "            \n",
    "            abstract = data['abstract'];\n",
    "            titles = data['titles'];\n",
    "            authors = data['authors'];\n",
    "            journal = data['journal'];\n",
    "\n",
    "            for (i = 0; i < x.length; i++) {\n",
    "                if(abstract[i].includes(text_value) || \n",
    "                   titles[i].includes(text_value) || \n",
    "                   authors[i].includes(text_value) || \n",
    "                   journal[i].includes(text_value)) {\n",
    "                    x[i] = x_backup[i];\n",
    "                    y[i] = y_backup[i];\n",
    "                } else {\n",
    "                    x[i] = undefined;\n",
    "                    y[i] = undefined;\n",
    "                }\n",
    "            }\n",
    "            \n",
    "\n",
    "\n",
    "        source.change.emit();\n",
    "        \"\"\")\n",
    "\n",
    "# option\n",
    "option = RadioButtonGroup(labels=[\"C-0\", \"C-1\", \"C-2\",\n",
    "                                  \"C-3\", \"C-4\", \"C-5\",\n",
    "                                  \"C-6\", \"C-7\", \"C-8\",\n",
    "                                  \"C-9\", \"C-10\", \"C-11\",\n",
    "                                  \"C-12\", \"C-13\", \"C-14\",\n",
    "                                  \"C-15\", \"C-16\", \"C-17\",\n",
    "                                  \"C-18\", \"C-19\", \"All\"], \n",
    "                          active=20)\n",
    "#option.js_on_click(callback)\n",
    "option.js_on_event('tap',callback)\n",
    "\n",
    "# search box\n",
    "keyword = TextInput(title=\"Search:\")\n",
    "keyword.js_on_event('tap', keyword_callback)\n",
    "\n",
    "#header\n",
    "header = Div(text=\"\"\"<h1>COVID-19 Literature Cluster</h1>\"\"\")\n",
    "\n",
    "# show\n",
    "show(column(header, column(option, keyword),p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please see the tools on right top.\n",
    "#### If the text doesn't fit in the screen on the above plot when hover, please try the 'Box Zoom' tool to zoom to the area where the target plot is. This will help the hover message to fit the screen. \n",
    "#### Use the 'Reset' button to revert the zoom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is adaption from the following kaggle notebook https://www.kaggle.com/maksimeren/covid-19-literature-clustering\n",
    "### You can find the full version of the interactive plot here on GitHub: \n",
    "#### https://maksimekin.github.io/COVID19-Literature-Clustering/plots/t-sne_covid-19_interactive.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
